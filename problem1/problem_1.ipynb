{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 1\n",
    "In this notebook, we use the following modules `numpy` and `minotaur_maze`. The latter is a home made module, where all the solutions to the questions are implemented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import minoutaur_maze as mz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: The Maze and the Random Minotaur\n",
    "\n",
    "The objective of problem 1 is to solve the shortest path problem in a maze. We start first by describing the maze as a numpy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting positions\n",
    "thomas_st = (0,0)\n",
    "minotaur_st = (6,5)\n",
    "\n",
    "# Description of the maze as a numpy array\n",
    "maze = np.array([\n",
    "    [0, 0, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 1, 1, 1],\n",
    "    [0, 0, 1, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 1, 1, 1, 0],\n",
    "    [0, 0, 0, 0, 1, 2, 0, 0]\n",
    "])\n",
    "# with the convention \n",
    "# 0 = empty cell\n",
    "# 1 = obstacle\n",
    "# 2 = exit of the Maze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `maze.draw_maze()` helps us draw the maze given its numpy array discription.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2656c8f438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mz.draw_maze(maze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDP formulation\n",
    "\n",
    "We propose the following MDP formulation: \n",
    "\n",
    "#### State space $\\mathcal{S}$\n",
    "We model the state space as the set of all possible positions of the player in the maze. Note that we exclude the obstacles' position since these are impossible states to be in for the player. Formally, the state space is\n",
    "\n",
    "\n",
    "$$\\mathcal{S} = \\big\\lbrace (i,j):\\textrm{such that the cell\n",
    "} (i,j) \\textrm{ is not an obstacle}\\big\\rbrace.$$\n",
    "> **Note:** The choice of state space is not unique. For instance one could consider $\\mathcal{S}$ to be the set of all positions in the  maze regardless of whether they correspond to an obstacle or not. But note that, this will increase the size $\\vert \\mathcal{S} \\vert $. This is fine for small mazes, but it leads to many redundant states as the maze dimension increases.\n",
    "\n",
    "#### Action space $\\mathcal{A}$\n",
    "We allow the player to chose to either move `left`, `right`, `down`, `up` or not move at all (`stay`). Note that sometimes the player cannot move in a certain direction because of an obstacle or a wall, yet we permit this to be action. We will see that this is not an issue as long as we define our transition probabilities and rewards appropriately.\n",
    "Formally, the action space is\n",
    "\n",
    "$$\\mathcal{A} = \\lbrace \\textrm{up}, \\textrm{ down}, \\textrm{ left}, \\textrm{ right}, \\textrm{ stay} \\rbrace.$$\n",
    "> **Note:** Once again, the choice of the action space is not unique. For instance one could remove the action `stay` from $\\mathcal{A}$, but then one should modify the transition probabilities accordingly as well as the rewards.  \n",
    "\n",
    "\n",
    "#### Transition probabilities $\\mathcal{P}$\n",
    "Note that there is no randomness involved upon taking an action by the player. As a consequence, the transition probabilities are deterministic. More precisely,   \n",
    "- If at state (or position) $s$ taking action (or move) $a$ does not lead to a wall or an obstacle but to another state (or position) $s'$, then $\\mathbb{P}(s' \\vert s, a) = 1$. \n",
    "- If at state (or position)  $s$ taking action (or move) $a$ leads to a wall or an obstacle, the player remains in his state (or position) $s$, then $\\mathbb{P}(s \\vert s, a) = 1$.\n",
    "\n",
    "> **Note**: Recall that for a fixed $s \\in \\mathcal{S}$ and $a \\in \\mathcal{A}$ we have $\\sum_{s' \\in \\mathcal{S}} \\mathbb{P}(s' \\vert s, a) = 1$, thus if for some $s' \\in \\mathcal{S}$  we have $\\mathbb{P}(s' \\vert s, a) = 1$, then for all $s'' \\in \\mathcal{S} \\backslash \\lbrace s'\\rbrace$ we have $\\mathbb{P}(s'' \\vert s, a) = 0$,\n",
    "\n",
    "#### Rewards $\\mathcal{R}$\n",
    "The objective of the player is to find the exit of the maze while avoiding the obstacles.    \n",
    "   - If at state $s$, taking action $a$, leads to a wall or an obstacle then $r(s,a) = -\\infty$\n",
    "   - If at state $s$, taking action $a$, leads to some other position in the maze that is not the exit nor a wall nor an obstacle, then $r(s, a) = -1$. \n",
    "   - If at state $s$, taking action $a$, leads to the exit then $r(s ,a) = 0$. \n",
    "> **Note**: Here the rewards are independent of time (i.e. $r_t(.,.) = r(.,.)$). \n",
    "\n",
    "\n",
    "### Implementation\n",
    "The above MDP formulation is implemented as a class ``maze.Maze`` in the file [maze.py](./maze.py) which given a matrix description of the maze instanciates the state space, action space, transition probabilities and rewards. \n",
    "\n",
    "> **Note:** In the class `maze.Maze` each state $s = (i,j)$ is given a unique identifier $s_{id} \\in \\lbrace 0, , \\dots, \\vert S \\vert -1 \\rbrace$. In other words, the state space from an implementation perspective is viewed as the set of integers $\\lbrace 0, , \\dots, \\vert S \\vert -1 \\rbrace$. This mapping is done via the dictionary `self.map` and its inverse mapping via the dictionary `self.states`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an environment maze\n",
    "env = mz.MinotaurMaze(maze)\n",
    "#env.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Dynamic Programming \n",
    "\n",
    "Before solving the MDP problem, recall that the finite horizon objective function is \n",
    "$$\n",
    "    \\mathbb{E} \\Big[ \\sum_{t=0}^T r(s_t, a_t) \\Big],\n",
    "$$\n",
    "where $T$ is the horizon.\n",
    "Recall the Bellman equation \n",
    "\\begin{equation}\n",
    "\\forall s \\in \\mathcal{S} \\qquad  V(s) = \\max_{a \\in \\mathcal{A}} \\Big\\lbrace r(s,a) + \\sum_{s' \\in \\mathcal{S}} \\mathbb{P}(s'\\vert s,a) V(s') \\Big\\rbrace\n",
    "\\end{equation}\n",
    "The dynamic programming solution for the finite horizon MDP problem consists of solving the above backward recursion. The method `maze.dynamic_programming` achieves this. \n",
    "> **Note:** To find the optimal path, it is enough to set the time horizon $T = 10$. Indeed, looking at the maze one can see that the player needs at least 10 steps to attain the exit $B$, if her starting position is at $A$. In fact if you set the time horizon less than 10, you will see that you do not find the optimal path.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finite horizon\n",
    "horizon = 20\n",
    "# Solve the MDP problem with dynamic programming \n",
    "V, policy = mz.dynamic_programming(env,horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate the shortest path starting from position A\n",
    "method = 'DynProg'\n",
    "start  = (thomas_st + minotaur_st)\n",
    "path = env.simulate(start, policy, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, 6, 5),\n",
       " (0, 0, 5, 5),\n",
       " (0, 0, 4, 5),\n",
       " (0, 0, 4, 6),\n",
       " (0, 0, 4, 7),\n",
       " (0, 0, 4, 6),\n",
       " (0, 0, 4, 5),\n",
       " (0, 1, 3, 5),\n",
       " (1, 1, 3, 6),\n",
       " (2, 1, 3, 7),\n",
       " (3, 1, 3, 6),\n",
       " (4, 1, 2, 6),\n",
       " (4, 2, 2, 7),\n",
       " (4, 3, 1, 7),\n",
       " (4, 4, 0, 7),\n",
       " (4, 5, 0, 6),\n",
       " (4, 6, 0, 7),\n",
       " (4, 7, 1, 7),\n",
       " (5, 7, 0, 7),\n",
       " (6, 7, 1, 7),\n",
       " (6, 6, 0, 7),\n",
       " (6, 5, 0, 6)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(path)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2642a18470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the shortest path \n",
    "mz.animate_solution(maze, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
